#include <algorithm>
#include <cfloat>
#include <vector>
#include <thrust/host_vector.h>
#include <thrust/device_vector.h>
#include <thrust/sort.h>
#include <thrust/unique.h>
#include <iterator>
#include <stdio.h>

#include "caffe/layer.hpp"
#include "caffe/util/math_functions.hpp"
#include "caffe/vision_layers.hpp"

namespace caffe {

template <typename Dtype>
__global__ void SoftmaxLossExpectationForwardGPU(const int nthreads,
          const Dtype* prob_data, const Dtype* label, Dtype* loss,
          const int num, const int dim, const int spatial_dim,
          const bool has_ignore_label_, const int ignore_label_, 
					const bool ignore_objectness_, const bool ignore_location_, const bool ignore_constraint_,
          Dtype* counts) {
 
	int max_pixels[21]; // Pixel indices for max pixel probability for each class 
	int len = 0;
  double sum_present_classes = 0;
  while (true) { // Gets all the unique numbers out of the 3rd channel
    int class_ = static_cast<int>(label[2*spatial_dim + len]);
		int start_index = class_ * spatial_dim;
		double max = 0;
		for (int i = start_index; i < start_index + spatial_dim; i++) {
			double pixel_class_prob = prob_data[i];
			if (pixel_class_prob > max) {
				max = pixel_class_prob;
				max_pixels[class_] = i;
			}
		}  
		if (class_ == 0) break; // After computing maximum pixel for 0-class
    len++;
  }

	CUDA_KERNEL_LOOP(index, nthreads) {
    //const int n = index / spatial_dim;
    const int s = index % spatial_dim;
    const int label_value = static_cast<int>(label[s]);
		const int num_supervised = 1; // Need to set this later! 
		const int num_unsupervised = spatial_dim; // For now, the number of pixels in the image

		int num_classes_in_image = 0;
		double sum_present_classes = 0;
		while (true) { // Gets all the unique numbers out of the 3rd channel
			int class_ = static_cast<int>(label[2*spatial_dim + num_classes_in_image]);
			if (class_ == 0) break;
			sum_present_classes += max(prob_data[class_ * spatial_dim + s], Dtype(FLT_MIN)); // P(class=c)  
      num_classes_in_image++;
		}

		const int L = num_classes_in_image + 1;	
		loss[index] = 0; // Initialize loss to be 0 no matter what
		double Sc = max(prob_data[label_value * spatial_dim + s], Dtype(FLT_MIN));

		// If it's the image-level labels case (no supervision)
		// Treat max pixel for the class as supervised
		if (ignore_location_ && (s == max_pixels[label_value])) {
			loss[index] -= (log( Sc ) / L);	
		} 

		// -------------------------------------

		// Unsupervised
		if (has_ignore_label_ && label_value == ignore_label_) {
			const int objectness = static_cast<int>(label[1 * spatial_dim + s]); // Value between 0 and 255
			const double S0 = max(prob_data[0 * spatial_dim + s], Dtype(FLT_MIN)); // P(class=0) in our model
      const double P = 1.0 - ((double)objectness / 255.0); // P(class=0) acording to prior

			if (!ignore_objectness_) {
				loss[index] -= (log( P*S0 + (1-P)*(1-S0) ) / num_unsupervised); 
			}
			if (!ignore_constraint_) {
				loss[index] -= (log( S0 + sum_present_classes  ) / num_unsupervised); 
			}

		// Supervised; we do know the target label: Loss(class=t) = -log(S_t)
		}	else {
			loss[index] -= (log( Sc ) / num_supervised);
		}
  }
}

template <typename Dtype>
void SoftmaxWithLossExpectationLayer<Dtype>::Forward_gpu(
    const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
  softmax_layer_->Forward(softmax_bottom_vec_, softmax_top_vec_);
  const Dtype* prob_data = prob_.gpu_data();
  const Dtype* label = bottom[1]->gpu_data();
  const int dim = prob_.count() / outer_num_;
  CHECK_EQ(outer_num_ * inner_num_ * 3, bottom[1]->count(0))
      << "Number of labels must match the number of predictions because there are three channels,"
      << "one for gt labels per pixel and one for objectness labels per pixel and one for unique classes; "
      << "e.g., if softmax axis == 1 and prediction shape is (N, C, H, W), "
      << "label count (number of labels) must be 3*N*H*W, "
      << "with integer values in {0, 1, ..., C-1}.";

  const int nthreads = outer_num_ * inner_num_;
  // Since this memory is not used for anything until it is overwritten
  // on the backward pass, we use it here to avoid having to allocate new GPU
  // memory to accumulate intermediate results in the kernel.
  Dtype* loss_data = bottom[0]->mutable_gpu_diff();
  // Similarly, this memory is never used elsewhere, and thus we can use it
  // to avoid having to allocate additional GPU memory.
  Dtype* counts = prob_.mutable_gpu_diff();

  // NOLINT_NEXT_LINE(whitespace/operators)
  SoftmaxLossExpectationForwardGPU<Dtype><<<CAFFE_GET_BLOCKS(nthreads),
      CAFFE_CUDA_NUM_THREADS>>>(nthreads, prob_data, label, loss_data,
      outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_, ignore_objectness_, ignore_location_, ignore_constraint_, counts);
  Dtype loss;
  caffe_gpu_asum(nthreads, loss_data, &loss);
  if (normalize_) {
    Dtype count;
    caffe_gpu_asum(nthreads, counts, &count);
    loss /= count;
  } else {
    loss /= outer_num_;
  }
  top[0]->mutable_cpu_data()[0] = loss;
  if (top.size() == 2) {
    top[1]->ShareData(prob_);
  }
}

template <typename Dtype>
__global__ void SoftmaxLossExpectationBackwardGPU(const int nthreads, const Dtype* prob_data, const Dtype* top,
          const Dtype* label, Dtype* bottom_diff, const int num, const int dim,
          const int spatial_dim, const bool has_ignore_label_,
          const int ignore_label_, const bool ignore_objectness_, const bool ignore_location_, const bool ignore_constraint_, Dtype* counts) {
  const int channels = dim / spatial_dim;

	int max_pixels[21]; // Pixel indices for max pixel probability for each class 
  int len = 0;
  double sum_present_classes = 0;
  while (true) { // Gets all the unique numbers out of the 3rd channel
    int class_ = static_cast<int>(label[2*spatial_dim + len]);
    int start_index = class_ * spatial_dim;
    double max = 0;
    for (int i = start_index; i < start_index + spatial_dim; i++) {
      double pixel_class_prob = prob_data[i];
      if (pixel_class_prob > max) {
        max = pixel_class_prob;
        max_pixels[class_] = i;
      }
    }
    if (class_ == 0) break; // After computing maximum pixel for 0-class
    len++;
  }


  CUDA_KERNEL_LOOP(index, nthreads) {
    //const int n = index / spatial_dim;
    const int s = index % spatial_dim;
    const int label_value = static_cast<int>(label[s]);
		const int num_supervised = 1; // Need to set this later!

		int num_classes_in_image = 0;
    double sum_present_classes = 0;
    while (true) { // Gets all the unique numbers out of the 3rd channel
      int class_ = static_cast<int>(label[2*spatial_dim + num_classes_in_image]);
      if (class_ == 0) break;
      sum_present_classes += max(prob_data[class_ * spatial_dim + s], Dtype(FLT_MIN)); // P(class=c)  
      num_classes_in_image++;
    }

    // Unsupervised
		if (has_ignore_label_ && label_value == ignore_label_) {
			const int objectness = static_cast<int>(label[spatial_dim + s]); // Value between 0 and 255
      const double S0 = max(prob_data[0 * spatial_dim + s], Dtype(FLT_MIN)); // P(bg) in our model
      const double P = 1.0 - ((double)objectness / 255.0); // P(bg) acording to prior
			const double S_label = bottom_diff[label_value * spatial_dim + s];

			// Iterates over all channels 
      for (int i = 0; i < channels; i++) {
				// Save S_i to multiply by 
				Si = bottom_diff[i * spatial_dim + s];
				bottom_diff[i * spatial_dim + s] = 0;
		
				// Checks if image contains this particular class 	
				bool img_contains_class = false;
    		while (true) {
      		int class_ = static_cast<int>(label[2*spatial_dim + len]);
      		if (class_ == 0) break; // We've reached the end of the present classes
      		if (class_ == i) img_contains_class = true;
    		}

				if (!ignore_objectness_) {
					double a_i;
					if (i == 0) a_i = P; // background
					else a_i = 1-P; // not background
					double denom = P*S0 + (1-P)*(1-S0); 
					bottom_diff[i * spatial_dim + s] += Si*(1 - (a_i / denom));	
				}
				if (!ignore_constraint_) {
					if (img_contains_class || i == 0) {
						double denom = S0 + sum_present_classes;
						bottom_diff[i * spatial_dim + s] += Si*(1 - (1 / denom)); 
					} // Otherwise grad is just S_i
					else {
						bottom_diff[i * spatial_dim + s] += Si;
					}
				}
			}

		// Supervised 
		} else {
			bottom_diff[label_value * spatial_dim + s] -= 1;
		}

		// -------------------------------------

		// If it's the image-level labels case (no supervision)
    // Treat max pixel for the class as supervised
    if (ignore_location_ && (s == max_pixels[label_value])) {
      bottom_diff[label_value * spatial_dim + s] -= 1;
		}     


    // If there are some clicks, then either:
		// (a) Ignore location (i.e. all pixels are unsupervised), or
    // (b) We do not know the target label because we don't have a user click 
		/*else*/ if (ignore_location_ || (has_ignore_label_ && label_value == ignore_label_)) {
			const int objectness = static_cast<int>(label[spatial_dim + s]); // Value between 0 and 255
      const double S0 = max(prob_data[0 * spatial_dim + s], Dtype(FLT_MIN)); // P(bg) in our model
      const double P = 1.0 - ((double)objectness / 255.0); // P(bg) acording to prior

			// Iterates over all channels 
			for (int i = 0; i < channels; i++) {
				// Checks if image contains this particular class 	
				bool img_contains_class = false;
    		while (true) {
      		int class_ = static_cast<int>(label[2*spatial_dim + len]);
      		if (class_ == 0) break; // We've reached the end of the present classes
      		if (class_ == i) img_contains_class = true;
    		}

				if (ignore_objectness_ && ignore_constraint_) { // No objectness, no constraint
					bottom_diff[i * spatial_dim + s] = 0;
					counts[index] = 0;
				} else if (!ignore_objectness_ && ignore_constraint_) { // Objectness, no constraint 
					double a_i;
					if (i == 0) a_i = P; // background
					else a_i = 1-P; // not background
					double denom = P*S0 + (1-P)*(1-S0); 
					bottom_diff[i * spatial_dim + s] *= (1 - (a_i / denom));
					counts[index] = 1; 
				} else if (ignore_objectness_ && !ignore_constraint_) { // No objectness, constraint
					if (img_contains_class || i == 0) {
						double denom = S0 + sum_present_classes;
						bottom_diff[i * spatial_dim + s] *= (1 - (1 / denom)); 
					}	// Otherwise grad is just S_i
					counts[index] = 1;
				} else if (!ignore_objectness_ && !ignore_constraint_) { // Objectness, constraint 
					if (len == 0) {
						bottom_diff[i * spatial_dim + s] = 0;
					}
					else if (img_contains_class || i == 0) {
						double a_i;
						if (i == 0) a_i = P; // background
						else a_i = (1-P)/len;
						double denom = P*S0 + ((1-P)/len)*sum_present_classes;
						bottom_diff[i * spatial_dim + s] *= (1 - (a_i / denom));
					} // Otherwise grad is just S_i
					counts[index] = 1;
				}
			}
    } else { // If we have a user click, the gradient calculation stays the same
      bottom_diff[label_value * spatial_dim + s] -= 1;
			counts[index] = 1;
    }
  }
}

template <typename Dtype>
void SoftmaxWithLossExpectationLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
    const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
  if (propagate_down[1]) {
    LOG(FATAL) << this->type()
               << " Layer cannot backpropagate to label inputs.";
  }
  if (propagate_down[0]) {
    Dtype* bottom_diff = bottom[0]->mutable_gpu_diff();
    const Dtype* prob_data = prob_.gpu_data();
    const Dtype* top_data = top[0]->gpu_data();
    caffe_gpu_memcpy(prob_.count() * sizeof(Dtype), prob_data, bottom_diff);
    const Dtype* label = bottom[1]->gpu_data();
    const int dim = prob_.count() / outer_num_;
    const int nthreads = outer_num_ * inner_num_;
    // Since this memory is never used for anything else,
    // we use to to avoid allocating new GPU memory.
    Dtype* counts = prob_.mutable_gpu_diff();

    // NOLINT_NEXT_LINE(whitespace/operators)
    SoftmaxLossExpectationBackwardGPU<Dtype><<<CAFFE_GET_BLOCKS(nthreads),
        CAFFE_CUDA_NUM_THREADS>>>(nthreads, prob_data, top_data, label, bottom_diff,
        outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_, ignore_objectness_, ignore_location_, ignore_constraint_, counts);
    const Dtype loss_weight = top[0]->cpu_diff()[0];
    if (normalize_) {
      Dtype count;
      caffe_gpu_asum(nthreads, counts, &count);
      caffe_gpu_scal(prob_.count(), loss_weight / count, bottom_diff);
    } else {
      caffe_gpu_scal(prob_.count(), loss_weight / outer_num_, bottom_diff);
    }
  }
}

INSTANTIATE_LAYER_GPU_FUNCS(SoftmaxWithLossExpectationLayer);

}  // namespace caffe
